{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías para conexión con la base de datos en PostgresSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías para entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceso a la base de datos de PostgresSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_35124\\1929048143.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar las variables de entorno desde un archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la URL de la base de datos desde las variables de entorno\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "# Establecer una conexión a la base de datos\n",
    "conn = psycopg2.connect(DATABASE_URL)\n",
    "\n",
    "# Definir la consulta SQL para seleccionar todos los datos de la tabla \"datos\"\n",
    "query = \"SELECT * FROM datos\"\n",
    "\n",
    "# Utilizar pandas para ejecutar la consulta y cargar los resultados en un DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()\n",
    "\n",
    "# Ahora, df contiene los datos de la tabla \"datos\" en un DataFrame. Comprobamos la cantidad de registros\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de los datos para entrenar al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para convertir la lista anidada en un numpy.ndarray\n",
    "def parse_vector(vector_list):\n",
    "    # Convierte la lista en un numpy.ndarray y luego redimensiona a (28, 28)\n",
    "    return np.array(vector_list).reshape(28, 28).astype(np.float32)\n",
    "\n",
    "# Aplica la función a la columna \"vector\" y crea una nueva columna \"VectorNum\"\n",
    "df['VectorNum'] = df['vector'].apply(parse_vector)\n",
    "\n",
    "# Convierte la columna 'VectorNum' en una lista de numpy.ndarray\n",
    "train_vectors = df['VectorNum'].to_list()\n",
    "\n",
    "# Convierte la lista en un numpy.ndarray de forma (n, 28, 28), donde n es el número de filas\n",
    "train_vectors = np.array(train_vectors)\n",
    "\n",
    "labels = df['etiqueta'].tolist()\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de retrained_model.h5 únicamente con los datos extraídos de la app (alojados en tabla datos, en la db de PostrgresSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "10/10 [==============================] - 2s 9ms/step - loss: 2.1292 - accuracy: 0.2567\n",
      "Epoch 2/6\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.4368 - accuracy: 0.6467\n",
      "Epoch 3/6\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9748 - accuracy: 0.7767\n",
      "Epoch 4/6\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6964 - accuracy: 0.8533\n",
      "Epoch 5/6\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5130 - accuracy: 0.8767\n",
      "Epoch 6/6\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.9267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ff2d889310>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un modelo secuencial\n",
    "retrained_model = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "retrained_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "retrained_model.fit(np.array(train_vectors), labels, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Una vez que haya terminado el entrenamiento, guardar el modelo nuevamente si es necesario\n",
    "retrained_model.save(\"retrained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reentrenamiento de mix_model.h5. Utiliza el model.h5 preentrenado con MNIST, y reentrena las últimas capas con los datos extraídos de la app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "10/10 [==============================] - 2s 12ms/step - loss: 2.2880 - accuracy: 0.6400\n",
      "Epoch 2/6\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3094 - accuracy: 0.7567\n",
      "Epoch 3/6\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.9607 - accuracy: 0.7800\n",
      "Epoch 4/6\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6329 - accuracy: 0.8300\n",
      "Epoch 5/6\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4777 - accuracy: 0.8733\n",
      "Epoch 6/6\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3293 - accuracy: 0.9033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ff2dee9950>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model = keras.models.load_model(\"mnist_model.h5\")\n",
    "mix_model = keras.models.clone_model(mnist_model)\n",
    "mix_model.set_weights(mnist_model.get_weights())\n",
    "for layer in mix_model.layers[:-12]: #las últimas tres capas\n",
    "    layer.trainable = False\n",
    "\n",
    "mix_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "mix_model.fit(np.array(train_vectors), labels, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez que haya terminado el entrenamiento, guardar el modelo\n",
    "mix_model.save(\"mix_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo con conjunto de datos mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos MNIST\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# Normalizar los valores de píxeles al rango [0, 1]\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 24s 11ms/step - loss: 0.2962 - accuracy: 0.9146\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1412 - accuracy: 0.9583\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1079 - accuracy: 0.9672\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0880 - accuracy: 0.9725\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0756 - accuracy: 0.9763\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0657 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ff25b88a90>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un modelo secuencial\n",
    "mnist_model = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "mnist_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "mnist_model.fit(np.array(train_images), train_labels, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Una vez que haya terminado el entrenamiento, guardar el modelo\n",
    "mnist_model.save(\"mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Comparativa de modelos\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = keras.models.load_model(\"mnist_model.h5\")\n",
    "mix_model = keras.models.load_model(\"mix_model.h5\")\n",
    "retrainedt_model = keras.models.load_model(\"retrained_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvSQL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
