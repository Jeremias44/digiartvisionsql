# DigiArtVision

# Modelo para reconocer d√≠gitos üìöüöÄüí°üë®‚Äçüíª

DigiArtVision es una aplicaci√≥n de reconocimiento de n√∫meros del 0 al 9 que utiliza distintos modelos en proceso de entrenamiento continuo. Los usuarios pueden dibujar n√∫meros en un lienzo y contribuir al entrenamiento de los modelos mediante feedback, adem√°s de comparar los resultados de los distintos modelos.

# Estructura del Repositorio

## Modelos

En la carpeta ra√≠z de este repositorio, encontrar√°s los tres modelos en formato .h5, disponibles para su uso y comparaci√≥n:

- **model_retrained.h5**: Este modelo se entrena continuamente a medida que los usuarios utilizan la aplicaci√≥n. Utiliza √∫nicamente los dibujos realizados en la app como datos de entrenamiento.

- **model_mnist.h5**: Es un modelo preentrenado que no se vuelve a entrenar con nuevos datos. Utiliza el conjunto de datos `MNIST` para su entrenamiento inicial.

- **model_mix.h5**: Este modelo utiliza los pesos del modelo mnist preentrenado y en las √∫ltimas capas de la red neuronal se reentrena con los nuevos datos obtenidos desde la aplicaci√≥n. Combina el conocimiento del modelo preentrenado con los nuevos datos.

## Aplicaci√≥n Streamlit

La aplicaci√≥n `appPIL.py` est√° desplegada desde un repositorio en `GitHub` a trav√©s de `Streamlit` y se encuentra configurada con las variables de entorno necesarias. El c√≥digo de la aplicaci√≥n establece la conexi√≥n con la base de datos `PostgreSQL`, donde se guardan los registros, que incluyen los vectores de los dibujos y las etiquetas correspondientes. La base de datos `PostgresSQL` est√° desplegada en `Render`, lo que significa que est√° disponible las 24 horas del d√≠a para acceder a los datos almacenados y cargar nuevos registros.

### Importaci√≥n de librer√≠as

```python
import streamlit as st
from tensorflow import keras
from keras.models import load_model
from PIL import Image
import numpy as np
from streamlit_drawable_canvas import st_canvas
import psycopg2
import os
from dotenv import load_dotenv
```

Este bloque de c√≥digo se encarga de importar las bibliotecas y m√≥dulos necesarios para el funcionamiento de la aplicaci√≥n. Aqu√≠ se describen las principales funciones de cada uno:

- `streamlit`: Es el marco de trabajo utilizado para crear aplicaciones web interactivas en Python.

- `keras` y `load_model`: Importa la biblioteca Keras, que se utiliza para cargar modelos de redes neuronales preentrenados y realizar predicciones.

- `PIL` (Pillow): Se utiliza para trabajar con im√°genes y, en este caso, para procesar las im√°genes dibujadas por los usuarios.

- `numpy`: Proporciona soporte para trabajar con matrices y arreglos multidimensionales, es esencial para el procesamiento de im√°genes y datos num√©ricos.

- `streamlit_drawable_canvas`: Es una extensi√≥n de Streamlit que permite a los usuarios dibujar en un lienzo interactivo.

- `psycopg2`: Se utiliza para conectarse a la base de datos PostgreSQL y realizar operaciones de base de datos.

- `os`: Proporciona funcionalidades para interactuar con el sistema operativo, en este caso, se utiliza para cargar variables de entorno.

- `dotenv`: Permite cargar las variables de entorno desde un archivo `.env`.

### Conexi√≥n a la Base de Datos PostgreSQL

```python
load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")
conn = psycopg2.connect(DATABASE_URL)

def save_data(vector, label):
    cursor = conn.cursor()
    insert_query = "INSERT INTO datos (vector, etiqueta) VALUES (ARRAY[%s], %s)"
    data = (vector, label)
    cursor.execute(insert_query, data)
    conn.commit()
    cursor.close()
```

En esta secci√≥n del c√≥digo, se establece la conexi√≥n con `PostgreSQL`, y se define una funci√≥n para guardar datos en ella. A continuaci√≥n, se detallan las acciones realizadas:

- **Obtenci√≥n de la URL de la Base de Datos**: 
  - `load_dotenv()`: Esta funci√≥n se utiliza para cargar variables de entorno desde un archivo `.env`. En este caso, se espera que en el archivo `.env` se defina una variable llamada "DATABASE_URL", que contiene la URL de la base de datos PostgreSQL.
  - `DATABASE_URL = os.getenv("DATABASE_URL")`: Aqu√≠ se obtiene la URL de la base de datos desde las variables de entorno y se almacena en la variable "DATABASE_URL". Esta URL suele contener informaci√≥n necesaria para la conexi√≥n, como el nombre de usuario, la contrase√±a, el host y el nombre de la base de datos.

- **Establecimiento de la Conexi√≥n a la Base de Datos**:
  - `conn = psycopg2.connect(DATABASE_URL)`: Se utiliza la biblioteca `psycopg2` para establecer una conexi√≥n a la base de datos PostgreSQL utilizando la URL obtenida anteriormente. Esto crea una conexi√≥n que se utilizar√° para interactuar con la base de datos.

- **Funci√≥n para Guardar Datos**:
  - `def save_data(vector, label)`: Se define una funci√≥n llamada "save_data" que toma dos argumentos, "vector" y "label".
  - `cursor = conn.cursor()`: Aqu√≠ se crea un cursor que se utilizar√° para ejecutar consultas en la base de datos. Un cursor es una especie de "puntero" que permite interactuar con la base de datos.
  - `insert_query = "INSERT INTO datos (vector, etiqueta) VALUES (ARRAY[%s], %s)"`: Se define una consulta SQL para insertar datos en la tabla "datos" de la base de datos. Los valores "vector" y "etiqueta" se insertan como par√°metros en la consulta para evitar problemas de seguridad y prevenir inyecciones SQL.
  - `data = (vector, label)`: Se crea una tupla llamada "data" que contiene los valores de "vector" y "label" que se desean insertar en la base de datos.
  - `cursor.execute(insert_query, data)`: Aqu√≠ se ejecuta la consulta de inserci√≥n con los datos proporcionados en la tupla "data".
  - `conn.commit()`: Se confirman los cambios en la base de datos, lo que significa que los datos se guardan de manera permanente.
  - `cursor.close()`: Finalmente, se cierra el cursor, liberando los recursos utilizados para la consulta.

Esta secci√≥n del c√≥digo es fundamental para guardar los datos generados por los usuarios en la base de datos PostgreSQL, lo que permite entrenar y mejorar el modelo de reconocimiento de n√∫meros.

### Interfaz de Usuario y Configuraci√≥n del Modelo

```python
st.title('Modelo para reconocer n√∫meros del 0 al 9 üìöüöÄüí°üë®‚Äçüíª')
st.subheader('Este modelo se encuentra en proceso de entrenamiento üèãÔ∏è‚Äç‚ôÇÔ∏è Pod√©s jugar las veces que quieras y estar√°s ayudando a entrenarlo! üí™')
st.write("## Para comenzar dibuj√° en el lienzo un n√∫mero del 0 al 9")

st.sidebar.title("Opciones de Dibujo")
background_color = st.sidebar.selectbox("Color del fondo", ("black","blue"), index=1)
stroke_width = st.sidebar.selectbox("Ancho del trazo", (20,30,40), index=1)
st.sidebar.title("Modelo a Utilizar")
st.sidebar.markdown('model_retrained.h5 es un modelo que se entrena √∫nicamente con los dibujos realizados por los usuarios de esta app')
st.sidebar.markdown('model_mnist.h5 es un modelo preentrenado con un dataset muy utilizado llamado MNIST')
st.sidebar.markdown('model_mix.h5 se entrena con los datos provenientes de ambas fuentes')
model = st.sidebar.selectbox("Modelo", ("model_retrained.h5","model_mnist.h5","model_mix.h5"), index=0)

loaded_model = load_model(model)

canvas = st_canvas(
    fill_color="black",  # Color de relleno de las formas
    stroke_width=stroke_width,  # Ancho del trazo
    stroke_color="white",  # Color del trazo
    background_color=background_color,  # Color de fondo del canvas
    width=280,  # Ancho del lienzo
    height=280,  # Alto del lienzo
    drawing_mode="freedraw",  # Modo de dibujo
    key="canvas",
)
```

Esta secci√≥n del c√≥digo se encarga de la interfaz de usuario y la configuraci√≥n del modelo. A continuaci√≥n, se detallan las acciones realizadas:

- **T√≠tulo y Subt√≠tulo**:
  - `st.title('Modelo para reconocer n√∫meros del 0 al 9 üìöüöÄüí°üë®‚Äçüíª')`: Se establece un t√≠tulo principal para la aplicaci√≥n web, que indica el prop√≥sito del modelo. El t√≠tulo incluye emojis para darle un toque visual y amigable.
  - `st.subheader('Este modelo se encuentra en proceso de entrenamiento üèãÔ∏è‚Äç‚ôÇÔ∏è Pod√©s jugar las veces que quieras y estar√°s ayudando a entrenarlo! üí™')`: Se agrega un subt√≠tulo que describe el estado de entrenamiento del modelo y anima a los usuarios a participar en su mejora.

- **Instrucciones Iniciales**:
  - `st.write("## Para comenzar dibuj√° en el lienzo un n√∫mero del 0 al 9")`: Se proporciona una instrucci√≥n inicial clara para los usuarios, invit√°ndolos a comenzar a dibujar un n√∫mero del 0 al 9 en el lienzo.

- **Configuraci√≥n de la Barra Lateral**:
  - `st.sidebar.title("Opciones de Dibujo")`: Se establece un t√≠tulo en la barra lateral que indica las opciones relacionadas con el dibujo.
  - `background_color = st.sidebar.selectbox("Color del fondo", ("black","blue"), index=1)`: Los usuarios pueden seleccionar el color de fondo para el lienzo a trav√©s de un cuadro de selecci√≥n en la barra lateral.
  - `stroke_width = st.sidebar.selectbox("Ancho del trazo", (20,30,40), index=1)`: Se permite a los usuarios elegir el ancho del trazo que desean utilizar para dibujar.
  - `st.sidebar.title("Modelo a Utilizar")`: Se agrega un t√≠tulo en la barra lateral que indica las opciones relacionadas con el modelo a utilizar.
  - Se proporciona informaci√≥n sobre tres modelos disponibles y la opci√≥n de seleccionar uno de ellos.

- **Carga del Modelo**:
  - `model = st.sidebar.selectbox("Modelo", ("model_retrained.h5","model_mnist.h5","model_mix.h5"), index=0)`: Se permite a los usuarios elegir el modelo que desean utilizar desde una lista desplegable en la barra lateral.
  - `loaded_model = load_model(model)`: El modelo seleccionado se carga desde un archivo .h5 para su uso en la aplicaci√≥n.

- **Creaci√≥n del Lienzo**:
  - `canvas = st_canvas(...)`: Se crea un lienzo en blanco en la interfaz de usuario que permitir√° a los usuarios dibujar el n√∫mero que deseen. Se especifican propiedades como el color de relleno, el ancho del trazo y el tama√±o del lienzo.

### Proceso de Predicci√≥n y Etiquetado

```python
if st.checkbox('Iniciar Predicciones'):
    image = Image.fromarray(canvas.image_data.astype('uint8'))
    st.write('Dibuj√° y borr√° las veces que quieras')

    scaled_image = image.resize((28, 28))
    scaled_image = scaled_image.convert('L')
    scaled_image = np.array(scaled_image)
    input_image = scaled_image.reshape(1, 28, 28, 1)
    input_image = input_image / 255.0
    predicted_number = loaded_model.predict(input_image)
    predicted_number = np.argmax(predicted_number)
    st.image(scaled_image, caption='Imagen procesada', width=140)
    st.subheader(f'Valor detectado: {predicted_number}')
    input_image_flat = input_image.reshape(-1)
    input_image_flat = input_image_flat.astype(np.float32)

    label = st.number_input("Verific√° que la etiqueta sea la correcta antes de guardarla. En caso de que sea incorrecta, por favor corregila (0,9):", 0, 9, predicted_number)     
    vector = input_image_flat.tolist()

if st.button('Guardar Etiqueta'):
    st.write('Gracias por ayudar a reentrenar el modelo')
    st.write("## ¬°Excelente trabajo! üèÖ")
    st.write('Si hac√©s click en la papelera pod√©s dibujar nuevamente un n√∫mero y seguir entrenando el modelo üòÉ')
    save_data(vector, label)
```

Esta secci√≥n del c√≥digo se encarga de la predicci√≥n de n√∫meros dibujados por el usuario en el lienzo y permite al usuario etiquetar el n√∫mero antes de guardarlo. A continuaci√≥n, se detallan las acciones realizadas:

- **Checkbox para Iniciar Predicciones**:
  - `if st.checkbox('Iniciar Predicciones'):`: Se utiliza un cuadro de verificaci√≥n (checkbox) que permite al usuario activar el proceso de predicci√≥n una vez que ha dibujado un n√∫mero en el lienzo.

- **Obtenci√≥n de la Imagen Dibujada**:
  - `image = Image.fromarray(canvas.image_data.astype('uint8'))`: Se convierte la informaci√≥n de la imagen dibujada en el lienzo en un objeto de imagen. La imagen se representa en formato uint8.
  - `st.write('Dibuj√° y borr√° las veces que quieras')`: Se muestra un mensaje indicando al usuario que puede seguir dibujando y borrando en el lienzo.

- **Preprocesamiento de la Imagen**:
  - `scaled_image = image.resize((28, 28))`: La imagen se escala para tener dimensiones de 28x28 p√≠xeles, que es la entrada esperada por el modelo.
  - `scaled_image = scaled_image.convert('L')`: La imagen se convierte a escala de grises para que tenga una sola capa de p√≠xeles en lugar de m√∫ltiples canales de color.
  - `scaled_image = np.array(scaled_image)`: La imagen se convierte en un arreglo NumPy para su procesamiento.
  - `input_image = scaled_image.reshape(1, 28, 28, 1)`: Se ajusta la forma de la imagen para que sea compatible con el modelo, agregando una dimensi√≥n de lote y configurando las dimensiones a 28x28x1.

- **Predicci√≥n con el Modelo**:
  - `predicted_number = loaded_model.predict(input_image)`: Se realiza la predicci√≥n del n√∫mero dibujado utilizando el modelo cargado. La salida es un arreglo de probabilidades.
  - `predicted_number = np.argmax(predicted_number)`: Se determina el n√∫mero predicho tomando el √≠ndice del valor m√°s alto en el arreglo de probabilidades.

- **Visualizaci√≥n de la Imagen y Resultado**:
  - `st.image(scaled_image, caption='Imagen procesada', width=140)`: Se muestra la imagen procesada en la interfaz de usuario con una leyenda.
  - `st.subheader(f'Valor detectado: {predicted_number}')`: Se muestra el n√∫mero predicho en la interfaz de usuario como resultado.

- **Etiquetado del N√∫mero y Preparaci√≥n de Datos para Guardar**:
  - `input_image_flat = input_image.reshape(-1)`: La imagen procesada se aplana a un arreglo unidimensional.
  - `input_image_flat = input_image_flat.astype(np.float32)`: El arreglo se convierte a tipo de dato float32 para su almacenamiento.
  - `label = st.number_input("Verific√° que la etiqueta sea la correcta antes de guardarla. En caso de que sea incorrecta, por favor corr√©gila (0,9):", 0, 9, predicted_number)`: Se permite al usuario verificar y, si es necesario, corregir la etiqueta del n√∫mero dibujado. La etiqueta se almacena en la variable `label`, y la representaci√≥n de la imagen en `input_image_flat`.

- **Bot√≥n para Guardar Etiqueta**:
  - `if st.button('Guardar Etiqueta'):`: Se presenta un bot√≥n que permite al usuario guardar la etiqueta asociada al n√∫mero dibujado.

- **Mensaje de Agradecimiento**:
  - Despu√©s de guardar la etiqueta, se muestra un mensaje agradeciendo al usuario por ayudar a reentrenar el modelo y se anima al usuario a seguir dibujando.

## Entorno Virtual

Para gestionar las dependencias de la aplicaci√≥n y garantizar la reproducibilidad, se utiliza un entorno virtual llamado `venvSQL`. En el archivo `requirements.txt`, encontrar√°s las librer√≠as y paquetes necesarios para ejecutar la aplicaci√≥n y conectar con la base de datos.

## Proceso de Reentrenamiento

El modelo se reentrena ejecutando el archivo `retrain.ipynb`. Este archivo accede a la base de datos PostgreSQL, realiza un preprocesamiento de los datos almacenados y, posteriormente, pasa estos datos a los modelos correspondientes para llevar a cabo el proceso de reentrenamiento. Al final del archivo `retrain.ipynb`, encontrar√°s un c√≥digo que eval√∫a los tres modelos en distintas m√©tricas para medir su rendimiento.

```python
import psycopg2
import pandas as pd
from dotenv import load_dotenv
import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
```

- **Importaci√≥n de Librer√≠as**:
  - `import psycopg2`: Se importa la librer√≠a `psycopg2`, que se utiliza para interactuar con la base de datos PostgreSQL y recuperar los datos para el reentrenamiento.
  - `import pandas as pd`: Se importa la librer√≠a `pandas` para el manejo de datos, lo que facilita la manipulaci√≥n de los datos recuperados de la base de datos.
  - `from dotenv import load_dotenv`: Se importa la funci√≥n `load_dotenv` de la librer√≠a `dotenv`, que se utiliza para cargar las variables de entorno que contienen informaci√≥n sensible, como las credenciales de la base de datos.
  - `import os`: Se importa la librer√≠a `os` para trabajar con rutas de archivos y cargar las variables de entorno.
  - `import numpy as np`: Se importa la librer√≠a `numpy` con el alias `np` para operaciones matem√°ticas y manipulaci√≥n de arreglos num√©ricos.
  - `import tensorflow as tf`: Se importa la librer√≠a `tensorflow` con el alias `tf` para el entrenamiento y reentrenamiento del modelo de reconocimiento.
  - `from tensorflow import keras`: Se importa la sublibrer√≠a `keras` de `tensorflow` para trabajar con modelos de redes neuronales.

Este conjunto de librer√≠as proporciona las herramientas necesarias para cargar datos desde la base de datos PostgreSQL, realizar el preprocesamiento de datos, y ejecutar el proceso de reentrenamiento del modelo. A medida que avances en el c√≥digo, estas librer√≠as se utilizar√°n para llevar a cabo estas tareas de manera eficiente.

La importaci√≥n de estas librer√≠as establece las bases para el reentrenamiento del modelo en funci√≥n de los nuevos datos proporcionados por los usuarios de la aplicaci√≥n. M√°s adelante en el c√≥digo, se realizar√°n tareas como la extracci√≥n de datos desde la base de datos, el preprocesamiento de im√°genes y el ajuste del modelo para mejorar su capacidad de reconocimiento de n√∫meros.

### Carga de Datos y Preprocesamiento

```python
load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")
conn = psycopg2.connect(DATABASE_URL)
query = "SELECT * FROM datos"
df = pd.read_sql_query(query, conn)
conn.close()

def parse_vector(vector_list):
    return np.array(vector_list).reshape(28, 28).astype(np.float32)

df['VectorNum'] = df['vector'].apply(parse_vector)
train_vectors = df['VectorNum'].to_list()
train_vectors = np.array(train_vectors)
labels = df['etiqueta'].tolist()
labels = np.array(labels)
```

En esta parte del c√≥digo, se realiza la carga de datos desde `PostgreSQL` y el preprocesamiento necesario para entrenar o reentrenar el modelo de reconocimiento de n√∫meros. A continuaci√≥n, se explican los pasos realizados:

- **Cargar Variables de Entorno**: Primero, se cargan las variables de entorno desde un archivo `.env` utilizando `load_dotenv()`. Esto es com√∫nmente utilizado para almacenar informaci√≥n sensible, como las credenciales de la base de datos.

- **Obtener la URL de la Base de Datos**: Se obtiene la URL de la base de datos PostgreSQL desde las variables de entorno mediante `os.getenv("DATABASE_URL")`. Esto proporciona la ubicaci√≥n y las credenciales necesarias para conectarse a la base de datos.

- **Establecer Conexi√≥n a la Base de Datos**: Se establece una conexi√≥n a la base de datos utilizando `psycopg2.connect(DATABASE_URL)`. Esto permite acceder a la base de datos y recuperar los datos almacenados.

- **Consultar y Cargar Datos en un DataFrame**: Se define una consulta SQL para seleccionar todos los datos de la tabla "datos" y se ejecuta utilizando Pandas. Los resultados se almacenan en un DataFrame llamado `df`, lo que facilita el manejo y procesamiento de los datos.

- **Cierre de la Conexi√≥n a la Base de Datos**: Una vez que los datos se han cargado en el DataFrame, se cierra la conexi√≥n a la base de datos con `conn.close()` para liberar recursos.

- **Transformaci√≥n de Datos**: Luego, se define una funci√≥n llamada `parse_vector` que se aplica a la columna "vector" del DataFrame. Esta funci√≥n convierte la lista anidada en un arreglo NumPy y redimensiona los datos a una forma de (28, 28) para que coincidan con el formato de las im√°genes.

- **Creaci√≥n de Arreglos NumPy para Entrenamiento**: Se crea un arreglo NumPy llamado `train_vectors` que contiene los datos preprocesados de las im√°genes en un formato adecuado para el entrenamiento del modelo. Adem√°s, se crea un arreglo `labels` que almacena las etiquetas asociadas a las im√°genes.

Este conjunto de pasos permite cargar los datos desde la base de datos, preprocesar las im√°genes y etiquetas, y prepararlos para ser utilizados en el proceso de entrenamiento o reentrenamiento del modelo de reconocimiento de n√∫meros. Estos datos son esenciales para mejorar y adaptar el modelo a nuevas muestras recopiladas desde la aplicaci√≥n.

### Creaci√≥n y Compilaci√≥n del Modelo de Red Neuronal

Esta parte del c√≥digo tiene como objetivo la creaci√≥n y entrenamiento del modelo de red neuronal. Utiliza la biblioteca TensorFlow y Keras para llevar a cabo estas tareas. A continuaci√≥n, se describen en detalle cada parte del c√≥digo:

### Creaci√≥n del Modelo

```python
retrained_model = keras.Sequential([
    layers.Flatten(input_shape=(28, 28)),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(10, activation='softmax')
])
```

- **keras.Sequential**: Se crea un modelo secuencial que es una secuencia lineal de capas de red neuronal.

- **layers.Flatten**: La primera capa, Flatten, transforma la imagen 2D (28x28 p√≠xeles) en un arreglo unidimensional de 784 elementos. Esto es necesario para aplanar la imagen y proporcionarla como entrada a la red neuronal.

- **layers.Dense(128, activation='relu')**: Esta es una capa oculta con 128 neuronas. La funci√≥n de activaci√≥n 'relu' (unidad lineal rectificada) se utiliza para introducir no linealidad en la red.

- **layers.Dropout(0.2)**: Se aplica un regularizador llamado "Dropout" con una tasa del 20%. Esto ayuda a prevenir el sobreajuste al desactivar aleatoriamente un 20% de las neuronas durante cada iteraci√≥n de entrenamiento.

- **layers.Dense(10, activation='softmax')**: La capa de salida tiene 10 neuronas, correspondientes a las 10 clases posibles (n√∫meros del 0 al 9). La funci√≥n de activaci√≥n 'softmax' se utiliza para obtener probabilidades de pertenencia a cada clase.


```python
retrained_model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
```

- **optimizer='adam'**: Se utiliza el optimizador Adam, que es un algoritmo de optimizaci√≥n que ajusta autom√°ticamente la tasa de aprendizaje durante el entrenamiento. Es ampliamente utilizado en tareas de entrenamiento de redes neuronales.

- **loss='sparse_categorical_crossentropy'**: La funci√≥n de p√©rdida se establece en 'sparse_categorical_crossentropy'. Esta funci√≥n de p√©rdida es com√∫nmente utilizada en problemas de clasificaci√≥n multiclase.

- **metrics=['accuracy']**: La m√©trica de evaluaci√≥n se establece en 'accuracy' para realizar un seguimiento de la precisi√≥n del modelo durante el entrenamiento.

```python
retrained_model.fit(np.array(train_vectors), labels, epochs=6)
retrained_model.save("model_retrained.h5")
```

- **np.array(train_vectors)**: Los datos de entrenamiento se proporcionan como un arreglo NumPy que contiene las im√°genes aplanadas.

- **labels**: Las etiquetas correspondientes a las im√°genes de entrenamiento.

- **epochs=6**: El modelo se entrena durante 6 √©pocas, lo que significa que pasa por todo el conjunto de datos de entrenamiento 6 veces. Durante el entrenamiento, el modelo ajusta sus pesos y bias para minimizar la funci√≥n de p√©rdida.

- **retrained_model.save("model_retrained.h5")**: # Una vez que se haya terminado el entrenamiento, se guarda el modelo

El archivo `retrain.ipynb` contin√∫a de manera similar con el entrenamiento de los restantes modelos `mix_model.h5` y `mnist_model.h5`. Luego pasa a la secci√≥n de Comparativa y Evaluaci√≥n de Modelos.





## Carpeta Media

Por √∫ltimo, en la carpeta `/media` se encuentran im√°genes y capturas de pantalla de la aplicaci√≥n en funcionamiento, con ejemplos de dibujos y etiquetas de predicciones


***
## Proyecto DigiArtVisionSQL

* [Jerem√≠as Pombo en LinkedIn](https://www.linkedin.com/in/jeremiaspombo/)

* [Repositorio de GitHub](https://github.com/Jeremias44/digiartvisionsql)

* [Acceder a la Aplicaci√≥n en Streamlit](https://digiartvisionsql.streamlit.app/)

## Contacto
Si tienes alguna pregunta o sugerencia, no dudes en contactarme a trav√©s de mi correo electr√≥nico: jeremiaspombo@outlook.com.

## C√≥digo Abierto
Este proyecto es de c√≥digo abierto, lo que significa que est√°s invitado a contribuir, realizar mejoras o utilizarlo en tus propios proyectos. ¬°Espero que disfrutes de DigiArtVisionSQL!